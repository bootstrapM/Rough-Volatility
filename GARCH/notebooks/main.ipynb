{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d51c6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: /Users/hraj/GitHub/RoughVolatility/Rough-Volatility/GARCH\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the GARCH directory to Python path\n",
    "garch_dir = '/Users/hraj/GitHub/RoughVolatility/Rough-Volatility/GARCH'\n",
    "if garch_dir not in sys.path:\n",
    "    sys.path.insert(0, garch_dir)\n",
    "print(f\"Added to path: {garch_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3d6553-5f86-49ea-95cb-b03676dde248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from simulate_data import generate_sample_data\n",
    "from garch_analysis import GARCHAnalyzer\n",
    "from visualization import VolatilityVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cc882",
   "metadata": {},
   "source": [
    "### Function to get S&P 500 data from Yahoo Finance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ed4111-07f6-4bd7-b7a0-62a0b85f2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_data(symbol: str = \"^GSPC\", years: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch market data from Yahoo Finance and prepare it for GARCH analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    symbol : str\n",
    "        Yahoo Finance ticker symbol (default: ^GSPC for S&P 500)\n",
    "    years : int\n",
    "        Number of years of historical data to fetch\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing returns and prices\n",
    "    \"\"\"\n",
    "    # Calculate start date\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=years*365)\n",
    "    \n",
    "    # Fetch data\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    data = ticker.history(start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate returns and handle NaN values\n",
    "    data['returns'] = data['Close'].pct_change()\n",
    "    \n",
    "    # Remove any NaN values\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Create DataFrame with required format\n",
    "    df = pd.DataFrame({\n",
    "        'returns': data['returns'],\n",
    "        'prices': data['Close']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nMarket Data Summary:\")\n",
    "    print(f\"Total observations: {len(df)}\")\n",
    "    print(f\"Date range: {df.index[0].strftime('%Y-%m-%d')} to {df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Average daily return: {df['returns'].mean():.6f}\")\n",
    "    print(f\"Daily volatility: {df['returns'].std():.6f}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a616160",
   "metadata": {},
   "source": [
    "### Function for performing EDA on the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3e97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(data: pd.DataFrame, title: str) -> GARCHAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze the given dataset and create visualizations.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing {title}...\")\n",
    "    \n",
    "    # Create analyzer and fit model\n",
    "    analyzer = GARCHAnalyzer(data['returns'])\n",
    "    params = analyzer.fit_model()\n",
    "    \n",
    "    # Get conditional volatility\n",
    "    data['conditional_volatility'] = analyzer.get_conditional_volatility()\n",
    "    \n",
    "    # Print model parameters\n",
    "    print(\"\\nEstimated GARCH parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # Calculate return statistics\n",
    "    stats = {\n",
    "        'mean': data['returns'].mean(),\n",
    "        'std': data['returns'].std(),\n",
    "        'skewness': data['returns'].skew(),\n",
    "        'kurtosis': data['returns'].kurtosis(),\n",
    "        'min': data['returns'].min(),\n",
    "        'max': data['returns'].max(),\n",
    "        'acf_squared_returns': pd.Series(data['returns']**2).autocorr()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nReturn series statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    prefix = title.lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    visualizer = VolatilityVisualizer(data)\n",
    "    \n",
    "    print(f\"\\nPlotting returns and volatility for {title}...\")\n",
    "    visualizer.plot_returns_and_volatility(title_prefix=prefix)\n",
    "    \n",
    "    print(f\"\\nPlotting evidence of volatility clustering for {title}...\")\n",
    "    visualizer.plot_volatility_clustering(title_prefix=prefix)\n",
    "    \n",
    "    print(f\"\\nPlotting returns distribution for {title}...\")\n",
    "    visualizer.plot_returns_distribution(title_prefix=prefix)\n",
    "    \n",
    "    if 'conditional_volatility' in data.columns:\n",
    "        visualizer.plot_qq_plot(title_prefix=prefix)\n",
    "    \n",
    "    return analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be67dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258cd87",
   "metadata": {},
   "source": [
    "## 1. Generating simulated data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa28c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating GARCH process data (with volatility clustering)...\n",
      "\n",
      "Analyzing GARCH process without shock...\n",
      "\n",
      "Analyzing GARCH Process (without shock)...\n",
      "\n",
      "Estimated GARCH parameters:\n",
      "omega: 0.0412\n",
      "alpha: 0.0900\n",
      "beta: 0.8584\n",
      "persistence: 0.9484\n",
      "log_likelihood: -1264.2782\n",
      "aic: 2534.5565\n",
      "bic: 2549.2797\n",
      "\n",
      "Return series statistics:\n",
      "mean: 0.0072\n",
      "std: 0.8811\n",
      "skewness: 0.0440\n",
      "kurtosis: 0.3594\n",
      "min: -3.3109\n",
      "max: 3.1140\n",
      "acf_squared_returns: 0.0362\n",
      "\n",
      "Plotting returns and volatility for GARCH Process (without shock)...\n",
      "\n",
      "Volatility Estimation Statistics:\n",
      "Mean Absolute Error: 0.102950\n",
      "Root Mean Square Error: 0.122959\n",
      "Correlation between True and Estimated: 0.980134\n",
      "\n",
      "Plotting evidence of volatility clustering for GARCH Process (without shock)...\n",
      "\n",
      "Volatility Estimation Statistics:\n",
      "Mean Absolute Error: 0.102950\n",
      "Root Mean Square Error: 0.122959\n",
      "Correlation between True and Estimated: 0.980134\n",
      "\n",
      "Plotting evidence of volatility clustering for GARCH Process (without shock)...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 10 out of 20\n",
      "First lag autocorrelation: 0.0362\n",
      "95% Confidence bound: ±0.0620\n",
      "Weak or no evidence of volatility clustering\n",
      "\n",
      "Plotting returns distribution for GARCH Process (without shock)...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 10 out of 20\n",
      "First lag autocorrelation: 0.0362\n",
      "95% Confidence bound: ±0.0620\n",
      "Weak or no evidence of volatility clustering\n",
      "\n",
      "Plotting returns distribution for GARCH Process (without shock)...\n",
      "\n",
      "Generating homoskedastic data (no volatility clustering)...\n",
      "\n",
      "Generating homoskedastic data (no volatility clustering)...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating GARCH process data (with volatility clustering)...\")\n",
    "garch_params = {\n",
    "    'omega': 0.05,   # Small constant term\n",
    "    'alpha': 0.15,   # Impact of past squared returns\n",
    "    'beta': 0.80     # High persistence in volatility\n",
    "}\n",
    "\n",
    "# First analyze without shock\n",
    "print(\"\\nAnalyzing GARCH process without shock...\")\n",
    "data_garch = generate_sample_data(n_samples=1000, garch_params=garch_params)\n",
    "analyzer_no_shock = analyze_data(data_garch, \"GARCH Process (without shock)\")\n",
    "\n",
    "# Generate homoskedastic data (no volatility clustering)\n",
    "print(\"\\nGenerating homoskedastic data (no volatility clustering)...\")\n",
    "data_homo = generate_sample_data(n_samples=1000, homoskedastic=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd45ca",
   "metadata": {},
   "source": [
    "![](plots/garch_process_without_shock_returns_volatility.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20562be2",
   "metadata": {},
   "source": [
    "![](plots/garch_process_without_shock_qq_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd252e",
   "metadata": {},
   "source": [
    "![](plots/garch_process_without_shock_returns_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70288d",
   "metadata": {},
   "source": [
    "![](plots/garch_process_without_shock_volatility_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2812db",
   "metadata": {},
   "source": [
    "## 2. Analyzing a Homoskedastic Process and comparing datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29838518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Homoskedastic Process (no volatility clustering)...\n",
      "\n",
      "Estimated GARCH parameters:\n",
      "omega: 0.0001\n",
      "alpha: 0.0155\n",
      "beta: 0.6422\n",
      "persistence: 0.6577\n",
      "log_likelihood: 2493.9651\n",
      "aic: -4981.9302\n",
      "bic: -4967.2069\n",
      "\n",
      "Return series statistics:\n",
      "mean: 0.0014\n",
      "std: 0.0199\n",
      "skewness: -0.0527\n",
      "kurtosis: 0.0609\n",
      "min: -0.0588\n",
      "max: 0.0639\n",
      "acf_squared_returns: 0.0033\n",
      "\n",
      "Plotting returns and volatility for Homoskedastic Process (no volatility clustering)...\n",
      "\n",
      "Volatility Estimation Statistics:\n",
      "Mean Absolute Error: 0.121361\n",
      "Root Mean Square Error: 0.121366\n",
      "Correlation between True and Estimated: nan\n",
      "\n",
      "Plotting evidence of volatility clustering for Homoskedastic Process (no volatility clustering)...\n",
      "\n",
      "Volatility Estimation Statistics:\n",
      "Mean Absolute Error: 0.121361\n",
      "Root Mean Square Error: 0.121366\n",
      "Correlation between True and Estimated: nan\n",
      "\n",
      "Plotting evidence of volatility clustering for Homoskedastic Process (no volatility clustering)...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 3 out of 20\n",
      "First lag autocorrelation: 0.0033\n",
      "95% Confidence bound: ±0.0620\n",
      "Weak or no evidence of volatility clustering\n",
      "\n",
      "Plotting returns distribution for Homoskedastic Process (no volatility clustering)...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 3 out of 20\n",
      "First lag autocorrelation: 0.0033\n",
      "95% Confidence bound: ±0.0620\n",
      "Weak or no evidence of volatility clustering\n",
      "\n",
      "Plotting returns distribution for Homoskedastic Process (no volatility clustering)...\n"
     ]
    }
   ],
   "source": [
    "analyzer_homo = analyze_data(data_homo, \"Homoskedastic Process (no volatility clustering)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aeb84",
   "metadata": {},
   "source": [
    "![](plots/homoskedastic_process_no_volatility_clustering_returns_volatility.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d480c",
   "metadata": {},
   "source": [
    "![](plots/homoskedastic_process_no_volatility_clustering_qq_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d50031",
   "metadata": {},
   "source": [
    "![](plots/homoskedastic_process_no_volatility_clustering_returns_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fd833",
   "metadata": {},
   "source": [
    "![](plots/homoskedastic_process_no_volatility_clustering_volatility_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c0e76",
   "metadata": {},
   "source": [
    "## 3. Analyzing GARCH process with shock..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0baaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing GARCH Process (with shock)...\n",
      "\n",
      "Estimated GARCH parameters:\n",
      "omega: 0.0294\n",
      "alpha: 0.0916\n",
      "beta: 0.8792\n",
      "persistence: 0.9709\n",
      "log_likelihood: -1332.0613\n",
      "aic: 2670.1225\n",
      "bic: 2684.8458\n",
      "\n",
      "Return series statistics:\n",
      "mean: 0.0190\n",
      "std: 0.9759\n",
      "skewness: 0.3590\n",
      "kurtosis: 2.5267\n",
      "min: -4.5812\n",
      "max: 5.4026\n",
      "acf_squared_returns: 0.0610\n",
      "\n",
      "Plotting returns and volatility for GARCH Process (with shock)...\n",
      "\n",
      "Volatility Estimation Statistics:\n",
      "Mean Absolute Error: 0.120988\n",
      "Root Mean Square Error: 0.165705\n",
      "Correlation between True and Estimated: 0.971202\n",
      "\n",
      "Plotting evidence of volatility clustering for GARCH Process (with shock)...\n",
      "\n",
      "Volatility Estimation Statistics:\n",
      "Mean Absolute Error: 0.120988\n",
      "Root Mean Square Error: 0.165705\n",
      "Correlation between True and Estimated: 0.971202\n",
      "\n",
      "Plotting evidence of volatility clustering for GARCH Process (with shock)...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 15 out of 20\n",
      "First lag autocorrelation: 0.0610\n",
      "95% Confidence bound: ±0.0620\n",
      "Weak or no evidence of volatility clustering\n",
      "\n",
      "Plotting returns distribution for GARCH Process (with shock)...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 15 out of 20\n",
      "First lag autocorrelation: 0.0610\n",
      "95% Confidence bound: ±0.0620\n",
      "Weak or no evidence of volatility clustering\n",
      "\n",
      "Plotting returns distribution for GARCH Process (with shock)...\n"
     ]
    }
   ],
   "source": [
    "shock_params = {\n",
    "    'time': 500,      # Shock at day 500\n",
    "    'magnitude': 8.0  # 8x normal volatility (increased from 5x)\n",
    "}\n",
    "data_garch_shock = generate_sample_data(\n",
    "    n_samples=1000, \n",
    "    garch_params=garch_params,\n",
    "    add_shock=True,\n",
    "    shock_params=shock_params\n",
    ")\n",
    "analyzer_shock = analyze_data(data_garch_shock, \"GARCH Process (with shock)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d788efa",
   "metadata": {},
   "source": [
    "![](plots/garch_process_with_shock_returns_volatility.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7b359",
   "metadata": {},
   "source": [
    "![](plots/garch_process_with_shock_qq_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe1d82",
   "metadata": {},
   "source": [
    "![](plots/garch_process_with_shock_returns_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48a45f",
   "metadata": {},
   "source": [
    "![](plots/garch_process_with_shock_volatility_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a8dba",
   "metadata": {},
   "source": [
    "## 4. Analyzing shock impact..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0348bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shock Impact Analysis:\n",
      "Pre-shock statistics:\n",
      "Mean volatility: 0.7796\n",
      "Max volatility: 1.0889\n",
      "\n",
      "Post-shock statistics:\n",
      "Mean volatility: 1.5699\n",
      "Max volatility: 2.3665\n",
      "Peak-to-pre-shock ratio: 3.04\n",
      "\n",
      "Shock half-life: 0 days\n",
      "\n",
      "Comparing GARCH persistence:\n",
      "\n",
      "Pre-shock model:\n",
      "Alpha: 0.0712\n",
      "Beta: 0.8456\n",
      "Persistence: 0.9168\n",
      "\n",
      "Post-shock model:\n",
      "Alpha: 0.0946\n",
      "Beta: 0.8784\n",
      "Persistence: 0.9731\n"
     ]
    }
   ],
   "source": [
    "shock_date = data_garch_shock.index[shock_params['time']]\n",
    "visualizer = VolatilityVisualizer(data_garch_shock)\n",
    "visualizer.plot_shock_analysis(shock_date)\n",
    "\n",
    "# Compare persistence before and after shock\n",
    "print(\"\\nComparing GARCH persistence:\")\n",
    "print(\"\\nPre-shock model:\")\n",
    "pre_shock_data = data_garch_shock.iloc[:shock_params['time']]\n",
    "analyzer_pre = GARCHAnalyzer(pre_shock_data['returns'])\n",
    "pre_params = analyzer_pre.fit_model()\n",
    "print(f\"Alpha: {pre_params['alpha']:.4f}\")\n",
    "print(f\"Beta: {pre_params['beta']:.4f}\")\n",
    "print(f\"Persistence: {pre_params['persistence']:.4f}\")\n",
    "\n",
    "print(\"\\nPost-shock model:\")\n",
    "post_shock_data = data_garch_shock.iloc[shock_params['time']:]\n",
    "analyzer_post = GARCHAnalyzer(post_shock_data['returns'])\n",
    "post_params = analyzer_post.fit_model()\n",
    "print(f\"Alpha: {post_params['alpha']:.4f}\")\n",
    "print(f\"Beta: {post_params['beta']:.4f}\")\n",
    "print(f\"Persistence: {post_params['persistence']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28aff1b",
   "metadata": {},
   "source": [
    "![](plots/_shock_analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bf019",
   "metadata": {},
   "source": [
    "## 5. Analyzing real market data (S&P 500)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c940fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Market Data Summary:\n",
      "Total observations: 1002\n",
      "Date range: 2021-05-21 to 2025-05-16\n",
      "Average daily return: 0.000422\n",
      "Daily volatility: 0.011276\n",
      "\n",
      "Analyzing S&P 500...\n",
      "\n",
      "Estimated GARCH parameters:\n",
      "omega: 0.0000\n",
      "alpha: 0.0926\n",
      "beta: 0.8920\n",
      "persistence: 0.9846\n",
      "log_likelihood: 3199.5227\n",
      "aic: -6393.0454\n",
      "bic: -6378.3161\n",
      "\n",
      "Return series statistics:\n",
      "mean: 0.0004\n",
      "std: 0.0113\n",
      "skewness: 0.1988\n",
      "kurtosis: 6.9413\n",
      "min: -0.0597\n",
      "max: 0.0952\n",
      "acf_squared_returns: 0.1592\n",
      "\n",
      "Plotting returns and volatility for S&P 500...\n",
      "\n",
      "Estimated Volatility Statistics:\n",
      "Mean: 0.101135\n",
      "Std Dev: 0.018013\n",
      "Min: 0.072493\n",
      "Max: 0.190174\n",
      "Median: 0.096745\n",
      "\n",
      "Plotting evidence of volatility clustering for S&P 500...\n",
      "\n",
      "Volatility Clustering Statistics:\n",
      "Number of significant lags: 7 out of 20\n",
      "First lag autocorrelation: 0.1592\n",
      "95% Confidence bound: ±0.0619\n",
      "Strong evidence of volatility clustering (significant first-lag autocorrelation)\n",
      "\n",
      "Plotting returns distribution for S&P 500...\n",
      "\n",
      "Comparison of Real vs Simulated Data:\n",
      "\n",
      "Real S&P 500 GARCH parameters:\n",
      "Alpha: 0.0926\n",
      "Beta: 0.8920\n",
      "Persistence: 0.9846\n",
      "\n",
      "Simulated GARCH parameters:\n",
      "Alpha: 0.1500\n",
      "Beta: 0.8000\n",
      "Persistence: 0.9500\n",
      "\n",
      "Analysis complete! Key observations:\n",
      "1. GARCH process shows clear volatility clustering\n",
      "2. Homoskedastic process shows constant volatility\n",
      "3. GARCH process has more realistic fat-tailed returns distribution\n",
      "4. Shock creates a significant spike in volatility (8x normal)\n",
      "5. Post-shock volatility persistence may differ from pre-shock\n",
      "6. Autocorrelation in squared returns is much stronger in GARCH process\n",
      "7. Real market data shows similar volatility clustering patterns\n",
      "8. S&P 500 GARCH parameters indicate market volatility characteristics\n"
     ]
    }
   ],
   "source": [
    "market_data = get_market_data(\"^GSPC\", years=4)\n",
    "analyzer_market = analyze_data(market_data, \"S&P 500\")\n",
    "\n",
    "# Compare simulated vs real data characteristics\n",
    "print(\"\\nComparison of Real vs Simulated Data:\")\n",
    "print(\"\\nReal S&P 500 GARCH parameters:\")\n",
    "market_params = analyzer_market.fit_model()\n",
    "print(f\"Alpha: {market_params['alpha']:.4f}\")\n",
    "print(f\"Beta: {market_params['beta']:.4f}\")\n",
    "print(f\"Persistence: {market_params['persistence']:.4f}\")\n",
    "\n",
    "print(\"\\nSimulated GARCH parameters:\")\n",
    "print(f\"Alpha: {garch_params['alpha']:.4f}\")\n",
    "print(f\"Beta: {garch_params['beta']:.4f}\")\n",
    "print(f\"Persistence: {garch_params['alpha'] + garch_params['beta']:.4f}\")\n",
    "\n",
    "print(\"\\nAnalysis complete! Key observations:\")\n",
    "print(\"1. GARCH process shows clear volatility clustering\")\n",
    "print(\"2. Homoskedastic process shows constant volatility\")\n",
    "print(\"3. GARCH process has more realistic fat-tailed returns distribution\")\n",
    "print(\"4. Shock creates a significant spike in volatility (8x normal)\")\n",
    "print(\"5. Post-shock volatility persistence may differ from pre-shock\")\n",
    "print(\"6. Autocorrelation in squared returns is much stronger in GARCH process\")\n",
    "print(\"7. Real market data shows similar volatility clustering patterns\")\n",
    "print(\"8. S&P 500 GARCH parameters indicate market volatility characteristics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120edf8",
   "metadata": {},
   "source": [
    "![](plots/s&p_500_returns_volatility.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cfd6b",
   "metadata": {},
   "source": [
    "![](plots/s&p_500_qq_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804d50d",
   "metadata": {},
   "source": [
    "![](plots/s&p_500_returns_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014d019",
   "metadata": {},
   "source": [
    "![](plots/s&p_500_volatility_clustering.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c4017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
